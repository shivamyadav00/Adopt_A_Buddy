{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PetIDNEW.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFMxB5GWym0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "dccb43ca-de4f-4122-8c13-be970a9de274"
      },
      "source": [
        "#imports \n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from imblearn.over_sampling import SMOTE "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrfNdOQfzF6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the DF\n",
        "train_df = pd.read_csv('trainPetID.csv')\n",
        "test_df = pd.read_csv('testPetID.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-klo0c0t0d3c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "6ffdbfc3-f1d2-490c-8341-5a77488fda67"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pet_id</th>\n",
              "      <th>issue_date</th>\n",
              "      <th>listing_date</th>\n",
              "      <th>condition</th>\n",
              "      <th>color_type</th>\n",
              "      <th>length(m)</th>\n",
              "      <th>height(cm)</th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>breed_category</th>\n",
              "      <th>pet_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ANSL_69903</td>\n",
              "      <td>2016-07-10 00:00:00</td>\n",
              "      <td>2016-09-21 16:25:00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Brown Tabby</td>\n",
              "      <td>0.80</td>\n",
              "      <td>7.78</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ANSL_66892</td>\n",
              "      <td>2013-11-21 00:00:00</td>\n",
              "      <td>2018-12-27 17:47:00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>White</td>\n",
              "      <td>0.72</td>\n",
              "      <td>14.19</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ANSL_69750</td>\n",
              "      <td>2014-09-28 00:00:00</td>\n",
              "      <td>2016-10-19 08:24:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Brown</td>\n",
              "      <td>0.15</td>\n",
              "      <td>40.90</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ANSL_71623</td>\n",
              "      <td>2016-12-31 00:00:00</td>\n",
              "      <td>2019-01-25 18:30:00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>White</td>\n",
              "      <td>0.62</td>\n",
              "      <td>17.82</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ANSL_57969</td>\n",
              "      <td>2017-09-28 00:00:00</td>\n",
              "      <td>2017-11-19 09:38:00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Black</td>\n",
              "      <td>0.50</td>\n",
              "      <td>11.06</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       pet_id           issue_date  ... breed_category  pet_category\n",
              "0  ANSL_69903  2016-07-10 00:00:00  ...            0.0             1\n",
              "1  ANSL_66892  2013-11-21 00:00:00  ...            0.0             2\n",
              "2  ANSL_69750  2014-09-28 00:00:00  ...            2.0             4\n",
              "3  ANSL_71623  2016-12-31 00:00:00  ...            0.0             2\n",
              "4  ANSL_57969  2017-09-28 00:00:00  ...            0.0             1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBsmaCFP0f_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5a24d2a-4c1e-4bae-9138-890b322f70d7"
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18834, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQv7BAHU0jA3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "2f504299-bbd4-496e-95e7-bba4b713c2b6"
      },
      "source": [
        "train_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 18834 entries, 0 to 18833\n",
            "Data columns (total 11 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   pet_id          18834 non-null  object \n",
            " 1   issue_date      18834 non-null  object \n",
            " 2   listing_date    18834 non-null  object \n",
            " 3   condition       17357 non-null  float64\n",
            " 4   color_type      18834 non-null  object \n",
            " 5   length(m)       18834 non-null  float64\n",
            " 6   height(cm)      18834 non-null  float64\n",
            " 7   X1              18834 non-null  int64  \n",
            " 8   X2              18834 non-null  int64  \n",
            " 9   breed_category  18834 non-null  float64\n",
            " 10  pet_category    18834 non-null  int64  \n",
            "dtypes: float64(4), int64(3), object(4)\n",
            "memory usage: 1.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7kyZ3MX0t_l",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "1. handle missing values\n",
        "2. convert into respective datatypes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qEitH7x0zu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fill missing values for condition column\n",
        "train_df['condition'].fillna('missing', inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF08eCWT5L6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "10db29c3-13eb-45c9-c53a-15da714ddc06"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pet_id</th>\n",
              "      <th>issue_date</th>\n",
              "      <th>listing_date</th>\n",
              "      <th>condition</th>\n",
              "      <th>color_type</th>\n",
              "      <th>length(m)</th>\n",
              "      <th>height(cm)</th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>breed_category</th>\n",
              "      <th>pet_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ANSL_69903</td>\n",
              "      <td>2016-07-10 00:00:00</td>\n",
              "      <td>2016-09-21 16:25:00</td>\n",
              "      <td>2</td>\n",
              "      <td>Brown Tabby</td>\n",
              "      <td>0.80</td>\n",
              "      <td>7.78</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ANSL_66892</td>\n",
              "      <td>2013-11-21 00:00:00</td>\n",
              "      <td>2018-12-27 17:47:00</td>\n",
              "      <td>1</td>\n",
              "      <td>White</td>\n",
              "      <td>0.72</td>\n",
              "      <td>14.19</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ANSL_69750</td>\n",
              "      <td>2014-09-28 00:00:00</td>\n",
              "      <td>2016-10-19 08:24:00</td>\n",
              "      <td>missing</td>\n",
              "      <td>Brown</td>\n",
              "      <td>0.15</td>\n",
              "      <td>40.90</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ANSL_71623</td>\n",
              "      <td>2016-12-31 00:00:00</td>\n",
              "      <td>2019-01-25 18:30:00</td>\n",
              "      <td>1</td>\n",
              "      <td>White</td>\n",
              "      <td>0.62</td>\n",
              "      <td>17.82</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ANSL_57969</td>\n",
              "      <td>2017-09-28 00:00:00</td>\n",
              "      <td>2017-11-19 09:38:00</td>\n",
              "      <td>2</td>\n",
              "      <td>Black</td>\n",
              "      <td>0.50</td>\n",
              "      <td>11.06</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       pet_id           issue_date  ... breed_category pet_category\n",
              "0  ANSL_69903  2016-07-10 00:00:00  ...            0.0            1\n",
              "1  ANSL_66892  2013-11-21 00:00:00  ...            0.0            2\n",
              "2  ANSL_69750  2014-09-28 00:00:00  ...            2.0            4\n",
              "3  ANSL_71623  2016-12-31 00:00:00  ...            0.0            2\n",
              "4  ANSL_57969  2017-09-28 00:00:00  ...            0.0            1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZIwmbJk1F_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to convert the columns in the respective data types\n",
        "def convert_to_datatype(df, cols, data_type):\n",
        "  for i in cols:\n",
        "    df[i] = df[i].astype(data_type)\n",
        "  return df\n",
        "\n",
        "# converting respective columns into respective data_types\n",
        "train_df = convert_to_datatype(train_df, ['breed_category'], 'int64')\n",
        "train_df = convert_to_datatype(train_df, ['pet_id', 'condition', 'color_type', 'X1', 'X2', 'breed_category', 'pet_category'], 'category')\n",
        "train_df = convert_to_datatype(train_df, ['issue_date', 'listing_date'], 'datetime64[ns]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzwiXQiW2xdj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "26314d62-9373-4adc-e47d-62655da86961"
      },
      "source": [
        "#validate changes\n",
        "train_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 18834 entries, 0 to 18833\n",
            "Data columns (total 11 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   pet_id          18834 non-null  category      \n",
            " 1   issue_date      18834 non-null  datetime64[ns]\n",
            " 2   listing_date    18834 non-null  datetime64[ns]\n",
            " 3   condition       18834 non-null  category      \n",
            " 4   color_type      18834 non-null  category      \n",
            " 5   length(m)       18834 non-null  float64       \n",
            " 6   height(cm)      18834 non-null  float64       \n",
            " 7   X1              18834 non-null  category      \n",
            " 8   X2              18834 non-null  category      \n",
            " 9   breed_category  18834 non-null  category      \n",
            " 10  pet_category    18834 non-null  category      \n",
            "dtypes: category(7), datetime64[ns](2), float64(2)\n",
            "memory usage: 1.5 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRcgWU6e29Ac",
        "colab_type": "text"
      },
      "source": [
        "#Feature Engineering\n",
        "\n",
        "1. DateTime Features\n",
        "2. Date Difference Features\n",
        "3. One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5E5wrh84JhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # def condition_breed_category(df, col1, col2):\n",
        "  # for i in col1: \n",
        "    # print (df[i])\n",
        "    # if df[i] == 'missing':\n",
        "      # for j in col2:\n",
        "        # df[j] = 2\n",
        "  # return df\n",
        "\n",
        "# train_df = condition_breed_category(train_df, ['condition'], ['breed_category'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B37UWisKoLqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.loc[train_df['condition'] == 'missing', ['breed_category']] = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANuLSdsW28lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For extracting additional date time features\n",
        "def create_datetime_features(df, cols): \n",
        "    for i in cols: \n",
        "        df[i + '_year'] = df[i].dt.year\n",
        "        df[i + '_month'] = df[i].dt.month\n",
        "        df[i + '_week'] = df[i].dt.week\n",
        "        df[i + '_day'] = df[i].dt.day\n",
        "        df[i + '_hour'] = df[i].dt.hour\n",
        "        df[i + '_dayofyear'] = df[i].dt.dayofyear\n",
        "        df[i + '_dayofweek'] = df[i].dt.dayofweek\n",
        "        df[i + '_quarter'] = df[i].dt.quarter\n",
        "        df[i + '_isweekend'] = np.where(df[ i + '_dayofweek'].isin([5,6]), 1, 0)\n",
        "    return df\n",
        "\n",
        "# Convert time data into differences\n",
        "train_df = create_datetime_features(train_df, ['issue_date', 'listing_date'])\n",
        "train_df['listing_issue_diff'] = train_df['listing_date'] - train_df['issue_date']\n",
        "train_df['listing_issue_diff'] = train_df['listing_issue_diff'].dt.days\n",
        "\n",
        "#One-Hot Encoding Categorical Data \n",
        "train_df = pd.get_dummies(columns = ['condition', 'color_type', 'X1', 'X2'], data= train_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl1PjRehgya7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#area feature\n",
        "train_df['area(m)'] = train_df['length(m)'] * train_df['height(cm)'] /100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSXXkTsl5eKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ac5dd12a-9aa8-4643-d960-33790cbe9416"
      },
      "source": [
        "train_df.info()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 18834 entries, 0 to 18833\n",
            "Columns: 117 entries, pet_id to area(m)\n",
            "dtypes: category(3), datetime64[ns](2), float64(3), int64(19), uint8(90)\n",
            "memory usage: 5.9 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fslFOuL68aHB",
        "colab_type": "text"
      },
      "source": [
        "#EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AFbjgE48c6L",
        "colab_type": "text"
      },
      "source": [
        "#Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ndhQ2RJ8vex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Splitting X & Y (dropping the categories in x that aren't needed)\n",
        "X = train_df.drop( ['breed_category', 'pet_category', 'issue_date', 'listing_date', 'pet_id'], axis = 1)\n",
        "y = train_df[ ['breed_category', 'pet_category'] ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NUD6rcDN_pZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols_to_scale = list(X)\n",
        "cols_to_scale.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBEuZHSbBNiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#performing z-score for normalizing the variables\n",
        "sc = StandardScaler()\n",
        "sc.fit(X[cols_to_scale])\n",
        "X_Scaled = pd.DataFrame(sc.transform(X[cols_to_scale]), columns= X.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOfNzEx4CGgD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "307b55e0-b405-46e4-adbb-06a50d9ce8ce"
      },
      "source": [
        "#Validate the original output\n",
        "X.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>length(m)</th>\n",
              "      <th>height(cm)</th>\n",
              "      <th>issue_date_year</th>\n",
              "      <th>issue_date_month</th>\n",
              "      <th>issue_date_week</th>\n",
              "      <th>issue_date_day</th>\n",
              "      <th>issue_date_hour</th>\n",
              "      <th>issue_date_dayofyear</th>\n",
              "      <th>issue_date_dayofweek</th>\n",
              "      <th>issue_date_quarter</th>\n",
              "      <th>issue_date_isweekend</th>\n",
              "      <th>listing_date_year</th>\n",
              "      <th>listing_date_month</th>\n",
              "      <th>listing_date_week</th>\n",
              "      <th>listing_date_day</th>\n",
              "      <th>listing_date_hour</th>\n",
              "      <th>listing_date_dayofyear</th>\n",
              "      <th>listing_date_dayofweek</th>\n",
              "      <th>listing_date_quarter</th>\n",
              "      <th>listing_date_isweekend</th>\n",
              "      <th>listing_issue_diff</th>\n",
              "      <th>condition_0.0</th>\n",
              "      <th>condition_1.0</th>\n",
              "      <th>condition_2.0</th>\n",
              "      <th>condition_missing</th>\n",
              "      <th>color_type_Agouti</th>\n",
              "      <th>color_type_Apricot</th>\n",
              "      <th>color_type_Black</th>\n",
              "      <th>color_type_Black Brindle</th>\n",
              "      <th>color_type_Black Smoke</th>\n",
              "      <th>color_type_Black Tabby</th>\n",
              "      <th>color_type_Black Tiger</th>\n",
              "      <th>color_type_Blue</th>\n",
              "      <th>color_type_Blue Cream</th>\n",
              "      <th>color_type_Blue Merle</th>\n",
              "      <th>color_type_Blue Point</th>\n",
              "      <th>color_type_Blue Smoke</th>\n",
              "      <th>color_type_Blue Tabby</th>\n",
              "      <th>color_type_Blue Tick</th>\n",
              "      <th>color_type_Blue Tiger</th>\n",
              "      <th>...</th>\n",
              "      <th>color_type_Silver Tabby</th>\n",
              "      <th>color_type_Tan</th>\n",
              "      <th>color_type_Torbie</th>\n",
              "      <th>color_type_Tortie</th>\n",
              "      <th>color_type_Tortie Point</th>\n",
              "      <th>color_type_Tricolor</th>\n",
              "      <th>color_type_White</th>\n",
              "      <th>color_type_Yellow</th>\n",
              "      <th>color_type_Yellow Brindle</th>\n",
              "      <th>X1_0</th>\n",
              "      <th>X1_1</th>\n",
              "      <th>X1_2</th>\n",
              "      <th>X1_3</th>\n",
              "      <th>X1_4</th>\n",
              "      <th>X1_5</th>\n",
              "      <th>X1_6</th>\n",
              "      <th>X1_7</th>\n",
              "      <th>X1_8</th>\n",
              "      <th>X1_9</th>\n",
              "      <th>X1_10</th>\n",
              "      <th>X1_11</th>\n",
              "      <th>X1_12</th>\n",
              "      <th>X1_13</th>\n",
              "      <th>X1_14</th>\n",
              "      <th>X1_15</th>\n",
              "      <th>X1_16</th>\n",
              "      <th>X1_17</th>\n",
              "      <th>X1_18</th>\n",
              "      <th>X1_19</th>\n",
              "      <th>X2_0</th>\n",
              "      <th>X2_1</th>\n",
              "      <th>X2_2</th>\n",
              "      <th>X2_3</th>\n",
              "      <th>X2_4</th>\n",
              "      <th>X2_5</th>\n",
              "      <th>X2_6</th>\n",
              "      <th>X2_7</th>\n",
              "      <th>X2_8</th>\n",
              "      <th>X2_9</th>\n",
              "      <th>area(m)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.0</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.00000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.00000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.00000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.00000</td>\n",
              "      <td>18834.000000</td>\n",
              "      <td>18834.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.502636</td>\n",
              "      <td>27.448832</td>\n",
              "      <td>2015.080121</td>\n",
              "      <td>6.824519</td>\n",
              "      <td>27.881332</td>\n",
              "      <td>15.750292</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.357757</td>\n",
              "      <td>3.011150</td>\n",
              "      <td>2.618031</td>\n",
              "      <td>0.294308</td>\n",
              "      <td>2017.426728</td>\n",
              "      <td>6.766805</td>\n",
              "      <td>27.523681</td>\n",
              "      <td>15.635818</td>\n",
              "      <td>14.20617</td>\n",
              "      <td>190.483487</td>\n",
              "      <td>3.063927</td>\n",
              "      <td>2.595784</td>\n",
              "      <td>0.291122</td>\n",
              "      <td>855.306786</td>\n",
              "      <td>0.333493</td>\n",
              "      <td>0.362058</td>\n",
              "      <td>0.226027</td>\n",
              "      <td>0.078422</td>\n",
              "      <td>0.000212</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.245301</td>\n",
              "      <td>0.003504</td>\n",
              "      <td>0.001699</td>\n",
              "      <td>0.002920</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.045237</td>\n",
              "      <td>0.000531</td>\n",
              "      <td>0.005522</td>\n",
              "      <td>0.001062</td>\n",
              "      <td>0.000319</td>\n",
              "      <td>0.020495</td>\n",
              "      <td>0.001115</td>\n",
              "      <td>0.000531</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000956</td>\n",
              "      <td>0.071626</td>\n",
              "      <td>0.012849</td>\n",
              "      <td>0.019433</td>\n",
              "      <td>0.00138</td>\n",
              "      <td>0.024902</td>\n",
              "      <td>0.130243</td>\n",
              "      <td>0.007593</td>\n",
              "      <td>0.000796</td>\n",
              "      <td>0.570882</td>\n",
              "      <td>0.002708</td>\n",
              "      <td>0.001274</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000372</td>\n",
              "      <td>0.000159</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.077519</td>\n",
              "      <td>0.002442</td>\n",
              "      <td>0.005628</td>\n",
              "      <td>0.000319</td>\n",
              "      <td>0.002814</td>\n",
              "      <td>0.003398</td>\n",
              "      <td>0.227249</td>\n",
              "      <td>0.000106</td>\n",
              "      <td>0.029415</td>\n",
              "      <td>0.032017</td>\n",
              "      <td>0.013805</td>\n",
              "      <td>0.029096</td>\n",
              "      <td>0.000159</td>\n",
              "      <td>0.000212</td>\n",
              "      <td>0.45094</td>\n",
              "      <td>0.009716</td>\n",
              "      <td>0.003398</td>\n",
              "      <td>0.067060</td>\n",
              "      <td>0.000637</td>\n",
              "      <td>0.000265</td>\n",
              "      <td>0.191568</td>\n",
              "      <td>0.00308</td>\n",
              "      <td>0.273123</td>\n",
              "      <td>0.137800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.288705</td>\n",
              "      <td>13.019781</td>\n",
              "      <td>3.103141</td>\n",
              "      <td>3.300786</td>\n",
              "      <td>14.423269</td>\n",
              "      <td>8.798332</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.024393</td>\n",
              "      <td>2.015388</td>\n",
              "      <td>1.077423</td>\n",
              "      <td>0.455743</td>\n",
              "      <td>0.945423</td>\n",
              "      <td>3.599175</td>\n",
              "      <td>15.648101</td>\n",
              "      <td>8.811040</td>\n",
              "      <td>4.06714</td>\n",
              "      <td>110.171288</td>\n",
              "      <td>1.978714</td>\n",
              "      <td>1.155092</td>\n",
              "      <td>0.454292</td>\n",
              "      <td>1096.674990</td>\n",
              "      <td>0.471473</td>\n",
              "      <td>0.480608</td>\n",
              "      <td>0.418268</td>\n",
              "      <td>0.268842</td>\n",
              "      <td>0.014572</td>\n",
              "      <td>0.026264</td>\n",
              "      <td>0.430277</td>\n",
              "      <td>0.059095</td>\n",
              "      <td>0.041186</td>\n",
              "      <td>0.053962</td>\n",
              "      <td>0.007287</td>\n",
              "      <td>0.207830</td>\n",
              "      <td>0.023037</td>\n",
              "      <td>0.074106</td>\n",
              "      <td>0.032571</td>\n",
              "      <td>0.017846</td>\n",
              "      <td>0.141689</td>\n",
              "      <td>0.033374</td>\n",
              "      <td>0.023037</td>\n",
              "      <td>...</td>\n",
              "      <td>0.030901</td>\n",
              "      <td>0.257874</td>\n",
              "      <td>0.112626</td>\n",
              "      <td>0.138045</td>\n",
              "      <td>0.03713</td>\n",
              "      <td>0.155830</td>\n",
              "      <td>0.336580</td>\n",
              "      <td>0.086807</td>\n",
              "      <td>0.028211</td>\n",
              "      <td>0.494963</td>\n",
              "      <td>0.051968</td>\n",
              "      <td>0.035675</td>\n",
              "      <td>0.007287</td>\n",
              "      <td>0.019276</td>\n",
              "      <td>0.012620</td>\n",
              "      <td>0.024161</td>\n",
              "      <td>0.267421</td>\n",
              "      <td>0.049361</td>\n",
              "      <td>0.074811</td>\n",
              "      <td>0.017846</td>\n",
              "      <td>0.052974</td>\n",
              "      <td>0.058196</td>\n",
              "      <td>0.419066</td>\n",
              "      <td>0.010305</td>\n",
              "      <td>0.168971</td>\n",
              "      <td>0.176049</td>\n",
              "      <td>0.116683</td>\n",
              "      <td>0.168081</td>\n",
              "      <td>0.012620</td>\n",
              "      <td>0.014572</td>\n",
              "      <td>0.49760</td>\n",
              "      <td>0.098095</td>\n",
              "      <td>0.058196</td>\n",
              "      <td>0.250132</td>\n",
              "      <td>0.025234</td>\n",
              "      <td>0.016292</td>\n",
              "      <td>0.393546</td>\n",
              "      <td>0.05541</td>\n",
              "      <td>0.445575</td>\n",
              "      <td>0.109404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1994.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2015.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-76.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>16.172500</td>\n",
              "      <td>2014.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>12.00000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.049447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>27.340000</td>\n",
              "      <td>2016.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>197.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>15.00000</td>\n",
              "      <td>206.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.109425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.760000</td>\n",
              "      <td>38.890000</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>277.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2018.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>17.00000</td>\n",
              "      <td>286.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1117.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.204836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>2019.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>366.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2019.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>23.00000</td>\n",
              "      <td>366.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8056.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.497800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 112 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          length(m)    height(cm)  ...          X2_9       area(m)\n",
              "count  18834.000000  18834.000000  ...  18834.000000  18834.000000\n",
              "mean       0.502636     27.448832  ...      0.273123      0.137800\n",
              "std        0.288705     13.019781  ...      0.445575      0.109404\n",
              "min        0.000000      5.000000  ...      0.000000      0.000000\n",
              "25%        0.250000     16.172500  ...      0.000000      0.049447\n",
              "50%        0.500000     27.340000  ...      0.000000      0.109425\n",
              "75%        0.760000     38.890000  ...      1.000000      0.204836\n",
              "max        1.000000     50.000000  ...      1.000000      0.497800\n",
              "\n",
              "[8 rows x 112 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OCf6oI6CNKy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "0322dd22-9bda-49c2-d1dc-fb2050bd08af"
      },
      "source": [
        "#Validate Scaled Output (Mean = 0, STDEV = 1)\n",
        "X_Scaled.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>length(m)</th>\n",
              "      <th>height(cm)</th>\n",
              "      <th>issue_date_year</th>\n",
              "      <th>issue_date_month</th>\n",
              "      <th>issue_date_week</th>\n",
              "      <th>issue_date_day</th>\n",
              "      <th>issue_date_hour</th>\n",
              "      <th>issue_date_dayofyear</th>\n",
              "      <th>issue_date_dayofweek</th>\n",
              "      <th>issue_date_quarter</th>\n",
              "      <th>issue_date_isweekend</th>\n",
              "      <th>listing_date_year</th>\n",
              "      <th>listing_date_month</th>\n",
              "      <th>listing_date_week</th>\n",
              "      <th>listing_date_day</th>\n",
              "      <th>listing_date_hour</th>\n",
              "      <th>listing_date_dayofyear</th>\n",
              "      <th>listing_date_dayofweek</th>\n",
              "      <th>listing_date_quarter</th>\n",
              "      <th>listing_date_isweekend</th>\n",
              "      <th>listing_issue_diff</th>\n",
              "      <th>condition_0.0</th>\n",
              "      <th>condition_1.0</th>\n",
              "      <th>condition_2.0</th>\n",
              "      <th>condition_missing</th>\n",
              "      <th>color_type_Agouti</th>\n",
              "      <th>color_type_Apricot</th>\n",
              "      <th>color_type_Black</th>\n",
              "      <th>color_type_Black Brindle</th>\n",
              "      <th>color_type_Black Smoke</th>\n",
              "      <th>color_type_Black Tabby</th>\n",
              "      <th>color_type_Black Tiger</th>\n",
              "      <th>color_type_Blue</th>\n",
              "      <th>color_type_Blue Cream</th>\n",
              "      <th>color_type_Blue Merle</th>\n",
              "      <th>color_type_Blue Point</th>\n",
              "      <th>color_type_Blue Smoke</th>\n",
              "      <th>color_type_Blue Tabby</th>\n",
              "      <th>color_type_Blue Tick</th>\n",
              "      <th>color_type_Blue Tiger</th>\n",
              "      <th>...</th>\n",
              "      <th>color_type_Silver Tabby</th>\n",
              "      <th>color_type_Tan</th>\n",
              "      <th>color_type_Torbie</th>\n",
              "      <th>color_type_Tortie</th>\n",
              "      <th>color_type_Tortie Point</th>\n",
              "      <th>color_type_Tricolor</th>\n",
              "      <th>color_type_White</th>\n",
              "      <th>color_type_Yellow</th>\n",
              "      <th>color_type_Yellow Brindle</th>\n",
              "      <th>X1_0</th>\n",
              "      <th>X1_1</th>\n",
              "      <th>X1_2</th>\n",
              "      <th>X1_3</th>\n",
              "      <th>X1_4</th>\n",
              "      <th>X1_5</th>\n",
              "      <th>X1_6</th>\n",
              "      <th>X1_7</th>\n",
              "      <th>X1_8</th>\n",
              "      <th>X1_9</th>\n",
              "      <th>X1_10</th>\n",
              "      <th>X1_11</th>\n",
              "      <th>X1_12</th>\n",
              "      <th>X1_13</th>\n",
              "      <th>X1_14</th>\n",
              "      <th>X1_15</th>\n",
              "      <th>X1_16</th>\n",
              "      <th>X1_17</th>\n",
              "      <th>X1_18</th>\n",
              "      <th>X1_19</th>\n",
              "      <th>X2_0</th>\n",
              "      <th>X2_1</th>\n",
              "      <th>X2_2</th>\n",
              "      <th>X2_3</th>\n",
              "      <th>X2_4</th>\n",
              "      <th>X2_5</th>\n",
              "      <th>X2_6</th>\n",
              "      <th>X2_7</th>\n",
              "      <th>X2_8</th>\n",
              "      <th>X2_9</th>\n",
              "      <th>area(m)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>18834.0</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "      <td>1.883400e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.478010e-16</td>\n",
              "      <td>1.412463e-17</td>\n",
              "      <td>-1.003676e-15</td>\n",
              "      <td>7.030432e-16</td>\n",
              "      <td>-6.201199e-16</td>\n",
              "      <td>1.855677e-16</td>\n",
              "      <td>-8.279614e-16</td>\n",
              "      <td>8.665210e-16</td>\n",
              "      <td>6.141065e-16</td>\n",
              "      <td>-3.254656e-17</td>\n",
              "      <td>-1.781550e-16</td>\n",
              "      <td>8.222440e-16</td>\n",
              "      <td>-1.328046e-15</td>\n",
              "      <td>1.271500e-15</td>\n",
              "      <td>-1.288066e-15</td>\n",
              "      <td>1.114749e-16</td>\n",
              "      <td>3.747515e-16</td>\n",
              "      <td>1.624879e-15</td>\n",
              "      <td>-4.122581e-16</td>\n",
              "      <td>3.689028e-16</td>\n",
              "      <td>1.611762e-15</td>\n",
              "      <td>8.913027e-16</td>\n",
              "      <td>-2.474791e-16</td>\n",
              "      <td>-5.439122e-16</td>\n",
              "      <td>-5.320217e-16</td>\n",
              "      <td>-7.345925e-16</td>\n",
              "      <td>-2.987064e-15</td>\n",
              "      <td>-1.219176e-15</td>\n",
              "      <td>-1.371870e-15</td>\n",
              "      <td>3.654764e-19</td>\n",
              "      <td>-6.827335e-17</td>\n",
              "      <td>1.039915e-15</td>\n",
              "      <td>-6.860585e-16</td>\n",
              "      <td>-3.147459e-16</td>\n",
              "      <td>4.956428e-16</td>\n",
              "      <td>7.069124e-16</td>\n",
              "      <td>-5.334651e-16</td>\n",
              "      <td>1.262446e-15</td>\n",
              "      <td>-1.482676e-15</td>\n",
              "      <td>7.581974e-16</td>\n",
              "      <td>...</td>\n",
              "      <td>6.830419e-16</td>\n",
              "      <td>9.302554e-17</td>\n",
              "      <td>7.529757e-16</td>\n",
              "      <td>1.483068e-16</td>\n",
              "      <td>3.917207e-16</td>\n",
              "      <td>1.208553e-15</td>\n",
              "      <td>1.389720e-16</td>\n",
              "      <td>6.228573e-16</td>\n",
              "      <td>-1.973204e-16</td>\n",
              "      <td>-5.018433e-16</td>\n",
              "      <td>-1.432540e-15</td>\n",
              "      <td>-2.307922e-15</td>\n",
              "      <td>-2.080669e-15</td>\n",
              "      <td>2.398778e-16</td>\n",
              "      <td>1.388446e-15</td>\n",
              "      <td>2.431479e-16</td>\n",
              "      <td>-1.443632e-16</td>\n",
              "      <td>2.845764e-16</td>\n",
              "      <td>-6.464276e-16</td>\n",
              "      <td>2.119940e-16</td>\n",
              "      <td>9.978096e-17</td>\n",
              "      <td>-2.862565e-16</td>\n",
              "      <td>7.379087e-17</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.794135e-16</td>\n",
              "      <td>-2.279748e-16</td>\n",
              "      <td>-6.981071e-16</td>\n",
              "      <td>9.243016e-17</td>\n",
              "      <td>-8.146823e-15</td>\n",
              "      <td>2.018962e-16</td>\n",
              "      <td>8.986004e-17</td>\n",
              "      <td>1.108956e-16</td>\n",
              "      <td>5.888297e-17</td>\n",
              "      <td>2.414620e-16</td>\n",
              "      <td>-5.702375e-16</td>\n",
              "      <td>1.373071e-16</td>\n",
              "      <td>1.496331e-16</td>\n",
              "      <td>1.384802e-16</td>\n",
              "      <td>-1.094144e-13</td>\n",
              "      <td>6.733019e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "      <td>1.000027e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.153414e+00</td>\n",
              "      <td>-5.210778e-02</td>\n",
              "      <td>-1.785145e-02</td>\n",
              "      <td>-5.312251e-02</td>\n",
              "      <td>-5.839261e-02</td>\n",
              "      <td>-5.422889e-01</td>\n",
              "      <td>-1.030545e-02</td>\n",
              "      <td>-1.740872e-01</td>\n",
              "      <td>-1.818668e-01</td>\n",
              "      <td>-1.183134e-01</td>\n",
              "      <td>-1.731135e-01</td>\n",
              "      <td>-1.262188e-02</td>\n",
              "      <td>-3.571998e-02</td>\n",
              "      <td>-7.286857e-03</td>\n",
              "      <td>-1.928228e-02</td>\n",
              "      <td>-1.262188e-02</td>\n",
              "      <td>-2.417419e-02</td>\n",
              "      <td>-2.898855e-01</td>\n",
              "      <td>-4.948102e-02</td>\n",
              "      <td>-7.523280e-02</td>\n",
              "      <td>-1.457487e-02</td>\n",
              "      <td>-9.062527e-01</td>\n",
              "      <td>-9.905456e-02</td>\n",
              "      <td>-5.839261e-02</td>\n",
              "      <td>-2.681041e-01</td>\n",
              "      <td>-2.524979e-02</td>\n",
              "      <td>-1.629564e-02</td>\n",
              "      <td>-4.867885e-01</td>\n",
              "      <td>-5.557922e-02</td>\n",
              "      <td>-6.129835e-01</td>\n",
              "      <td>-1.259587e+00</td>\n",
              "      <td>-1.457487e-02</td>\n",
              "      <td>-2.628151e-02</td>\n",
              "      <td>-5.701155e-01</td>\n",
              "      <td>-5.930113e-02</td>\n",
              "      <td>-4.125466e-02</td>\n",
              "      <td>-5.411842e-02</td>\n",
              "      <td>-7.286857e-03</td>\n",
              "      <td>-2.176711e-01</td>\n",
              "      <td>-2.304857e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.628151e-02</td>\n",
              "      <td>-3.496697e-02</td>\n",
              "      <td>-9.458472e-02</td>\n",
              "      <td>-6.448774e-02</td>\n",
              "      <td>-3.571998e-02</td>\n",
              "      <td>-1.457487e-02</td>\n",
              "      <td>-3.092948e-02</td>\n",
              "      <td>-2.777622e-01</td>\n",
              "      <td>-1.140892e-01</td>\n",
              "      <td>-1.407766e-01</td>\n",
              "      <td>-3.718051e-02</td>\n",
              "      <td>-1.598052e-01</td>\n",
              "      <td>-3.869711e-01</td>\n",
              "      <td>-8.746851e-02</td>\n",
              "      <td>-2.823237e-02</td>\n",
              "      <td>-7.073602e-01</td>\n",
              "      <td>-7.533529e-01</td>\n",
              "      <td>-5.404030e-01</td>\n",
              "      <td>-2.917111e-01</td>\n",
              "      <td>-1.724255e+00</td>\n",
              "      <td>-1.676532e+00</td>\n",
              "      <td>-1.494119e+00</td>\n",
              "      <td>-1.894224e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-6.457934e-01</td>\n",
              "      <td>-1.764633e+00</td>\n",
              "      <td>-1.501800e+00</td>\n",
              "      <td>-1.863797e+00</td>\n",
              "      <td>-6.793336e+00</td>\n",
              "      <td>-1.741047e+00</td>\n",
              "      <td>-1.661121e+00</td>\n",
              "      <td>-1.548484e+00</td>\n",
              "      <td>-1.719945e+00</td>\n",
              "      <td>-3.493007e+00</td>\n",
              "      <td>-6.408439e-01</td>\n",
              "      <td>-1.602300e+00</td>\n",
              "      <td>-1.381558e+00</td>\n",
              "      <td>-1.695055e+00</td>\n",
              "      <td>-2.566887e+00</td>\n",
              "      <td>-8.492320e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-1.153414e+00</td>\n",
              "      <td>-5.210778e-02</td>\n",
              "      <td>-1.785145e-02</td>\n",
              "      <td>-5.312251e-02</td>\n",
              "      <td>-5.839261e-02</td>\n",
              "      <td>-5.422889e-01</td>\n",
              "      <td>-1.030545e-02</td>\n",
              "      <td>-1.740872e-01</td>\n",
              "      <td>-1.818668e-01</td>\n",
              "      <td>-1.183134e-01</td>\n",
              "      <td>-1.731135e-01</td>\n",
              "      <td>-1.262188e-02</td>\n",
              "      <td>-3.571998e-02</td>\n",
              "      <td>-7.286857e-03</td>\n",
              "      <td>-1.928228e-02</td>\n",
              "      <td>-1.262188e-02</td>\n",
              "      <td>-2.417419e-02</td>\n",
              "      <td>-2.898855e-01</td>\n",
              "      <td>-4.948102e-02</td>\n",
              "      <td>-7.523280e-02</td>\n",
              "      <td>-1.457487e-02</td>\n",
              "      <td>-9.062527e-01</td>\n",
              "      <td>-9.905456e-02</td>\n",
              "      <td>-5.839261e-02</td>\n",
              "      <td>-2.681041e-01</td>\n",
              "      <td>-2.524979e-02</td>\n",
              "      <td>-1.629564e-02</td>\n",
              "      <td>-4.867885e-01</td>\n",
              "      <td>-5.557922e-02</td>\n",
              "      <td>-6.129835e-01</td>\n",
              "      <td>-8.076044e-01</td>\n",
              "      <td>-1.457487e-02</td>\n",
              "      <td>-2.628151e-02</td>\n",
              "      <td>-5.701155e-01</td>\n",
              "      <td>-5.930113e-02</td>\n",
              "      <td>-4.125466e-02</td>\n",
              "      <td>-5.411842e-02</td>\n",
              "      <td>-7.286857e-03</td>\n",
              "      <td>-2.176711e-01</td>\n",
              "      <td>-2.304857e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.628151e-02</td>\n",
              "      <td>-3.496697e-02</td>\n",
              "      <td>-9.458472e-02</td>\n",
              "      <td>-6.448774e-02</td>\n",
              "      <td>-3.571998e-02</td>\n",
              "      <td>-1.457487e-02</td>\n",
              "      <td>-3.092948e-02</td>\n",
              "      <td>-2.777622e-01</td>\n",
              "      <td>-1.140892e-01</td>\n",
              "      <td>-1.407766e-01</td>\n",
              "      <td>-3.718051e-02</td>\n",
              "      <td>-1.598052e-01</td>\n",
              "      <td>-3.869711e-01</td>\n",
              "      <td>-8.746851e-02</td>\n",
              "      <td>-2.823237e-02</td>\n",
              "      <td>-7.073602e-01</td>\n",
              "      <td>-7.533529e-01</td>\n",
              "      <td>-5.404030e-01</td>\n",
              "      <td>-2.917111e-01</td>\n",
              "      <td>-8.661153e-01</td>\n",
              "      <td>-8.809054e-01</td>\n",
              "      <td>-9.979238e-01</td>\n",
              "      <td>-8.152481e-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-6.457934e-01</td>\n",
              "      <td>-8.557340e-01</td>\n",
              "      <td>-5.736349e-01</td>\n",
              "      <td>-8.237832e-01</td>\n",
              "      <td>-3.480827e-01</td>\n",
              "      <td>-8.750881e-01</td>\n",
              "      <td>-8.666424e-01</td>\n",
              "      <td>-1.043092e+00</td>\n",
              "      <td>-9.030132e-01</td>\n",
              "      <td>-5.424520e-01</td>\n",
              "      <td>-6.408439e-01</td>\n",
              "      <td>-7.687535e-01</td>\n",
              "      <td>-5.158030e-01</td>\n",
              "      <td>-9.281680e-01</td>\n",
              "      <td>-4.513744e-01</td>\n",
              "      <td>-6.714171e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8.669914e-01</td>\n",
              "      <td>-5.210778e-02</td>\n",
              "      <td>-1.785145e-02</td>\n",
              "      <td>-5.312251e-02</td>\n",
              "      <td>-5.839261e-02</td>\n",
              "      <td>-5.422889e-01</td>\n",
              "      <td>-1.030545e-02</td>\n",
              "      <td>-1.740872e-01</td>\n",
              "      <td>-1.818668e-01</td>\n",
              "      <td>-1.183134e-01</td>\n",
              "      <td>-1.731135e-01</td>\n",
              "      <td>-1.262188e-02</td>\n",
              "      <td>-3.571998e-02</td>\n",
              "      <td>-7.286857e-03</td>\n",
              "      <td>-1.928228e-02</td>\n",
              "      <td>-1.262188e-02</td>\n",
              "      <td>-2.417419e-02</td>\n",
              "      <td>-2.898855e-01</td>\n",
              "      <td>-4.948102e-02</td>\n",
              "      <td>-7.523280e-02</td>\n",
              "      <td>-1.457487e-02</td>\n",
              "      <td>-9.062527e-01</td>\n",
              "      <td>-9.905456e-02</td>\n",
              "      <td>-5.839261e-02</td>\n",
              "      <td>-2.681041e-01</td>\n",
              "      <td>-2.524979e-02</td>\n",
              "      <td>-1.629564e-02</td>\n",
              "      <td>-4.867885e-01</td>\n",
              "      <td>-5.557922e-02</td>\n",
              "      <td>-6.129835e-01</td>\n",
              "      <td>-2.593659e-01</td>\n",
              "      <td>-1.457487e-02</td>\n",
              "      <td>-2.628151e-02</td>\n",
              "      <td>-5.701155e-01</td>\n",
              "      <td>-5.930113e-02</td>\n",
              "      <td>-4.125466e-02</td>\n",
              "      <td>-5.411842e-02</td>\n",
              "      <td>-7.286857e-03</td>\n",
              "      <td>-2.176711e-01</td>\n",
              "      <td>-2.304857e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.628151e-02</td>\n",
              "      <td>-3.496697e-02</td>\n",
              "      <td>-9.458472e-02</td>\n",
              "      <td>-6.448774e-02</td>\n",
              "      <td>-3.571998e-02</td>\n",
              "      <td>-1.457487e-02</td>\n",
              "      <td>-3.092948e-02</td>\n",
              "      <td>-2.777622e-01</td>\n",
              "      <td>-1.140892e-01</td>\n",
              "      <td>-1.407766e-01</td>\n",
              "      <td>-3.718051e-02</td>\n",
              "      <td>-1.598052e-01</td>\n",
              "      <td>-3.869711e-01</td>\n",
              "      <td>-8.746851e-02</td>\n",
              "      <td>-2.823237e-02</td>\n",
              "      <td>-7.073602e-01</td>\n",
              "      <td>-7.533529e-01</td>\n",
              "      <td>-5.404030e-01</td>\n",
              "      <td>-2.917111e-01</td>\n",
              "      <td>-8.359228e-03</td>\n",
              "      <td>2.838204e-02</td>\n",
              "      <td>-5.532604e-03</td>\n",
              "      <td>4.595292e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-6.457934e-01</td>\n",
              "      <td>5.316467e-02</td>\n",
              "      <td>3.545300e-01</td>\n",
              "      <td>7.756203e-02</td>\n",
              "      <td>2.964426e-01</td>\n",
              "      <td>-9.129487e-03</td>\n",
              "      <td>4.133354e-02</td>\n",
              "      <td>-3.230817e-02</td>\n",
              "      <td>1.408436e-01</td>\n",
              "      <td>1.951866e-01</td>\n",
              "      <td>-6.408439e-01</td>\n",
              "      <td>6.479304e-02</td>\n",
              "      <td>3.499517e-01</td>\n",
              "      <td>1.582547e-01</td>\n",
              "      <td>-4.513744e-01</td>\n",
              "      <td>-4.224762e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.669914e-01</td>\n",
              "      <td>-5.210778e-02</td>\n",
              "      <td>-1.785145e-02</td>\n",
              "      <td>-5.312251e-02</td>\n",
              "      <td>-5.839261e-02</td>\n",
              "      <td>-5.422889e-01</td>\n",
              "      <td>-1.030545e-02</td>\n",
              "      <td>-1.740872e-01</td>\n",
              "      <td>-1.818668e-01</td>\n",
              "      <td>-1.183134e-01</td>\n",
              "      <td>-1.731135e-01</td>\n",
              "      <td>-1.262188e-02</td>\n",
              "      <td>-3.571998e-02</td>\n",
              "      <td>-7.286857e-03</td>\n",
              "      <td>-1.928228e-02</td>\n",
              "      <td>-1.262188e-02</td>\n",
              "      <td>-2.417419e-02</td>\n",
              "      <td>-2.898855e-01</td>\n",
              "      <td>-4.948102e-02</td>\n",
              "      <td>-7.523280e-02</td>\n",
              "      <td>-1.457487e-02</td>\n",
              "      <td>1.103445e+00</td>\n",
              "      <td>-9.905456e-02</td>\n",
              "      <td>-5.839261e-02</td>\n",
              "      <td>-2.681041e-01</td>\n",
              "      <td>-2.524979e-02</td>\n",
              "      <td>-1.629564e-02</td>\n",
              "      <td>-4.867885e-01</td>\n",
              "      <td>-5.557922e-02</td>\n",
              "      <td>1.631365e+00</td>\n",
              "      <td>6.127550e-01</td>\n",
              "      <td>-1.457487e-02</td>\n",
              "      <td>-2.628151e-02</td>\n",
              "      <td>-5.701155e-01</td>\n",
              "      <td>-5.930113e-02</td>\n",
              "      <td>-4.125466e-02</td>\n",
              "      <td>-5.411842e-02</td>\n",
              "      <td>-7.286857e-03</td>\n",
              "      <td>-2.176711e-01</td>\n",
              "      <td>-2.304857e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.628151e-02</td>\n",
              "      <td>-3.496697e-02</td>\n",
              "      <td>-9.458472e-02</td>\n",
              "      <td>-6.448774e-02</td>\n",
              "      <td>-3.571998e-02</td>\n",
              "      <td>-1.457487e-02</td>\n",
              "      <td>-3.092948e-02</td>\n",
              "      <td>-2.777622e-01</td>\n",
              "      <td>-1.140892e-01</td>\n",
              "      <td>-1.407766e-01</td>\n",
              "      <td>-3.718051e-02</td>\n",
              "      <td>-1.598052e-01</td>\n",
              "      <td>-3.869711e-01</td>\n",
              "      <td>-8.746851e-02</td>\n",
              "      <td>-2.823237e-02</td>\n",
              "      <td>1.413707e+00</td>\n",
              "      <td>1.327399e+00</td>\n",
              "      <td>-5.404030e-01</td>\n",
              "      <td>-2.917111e-01</td>\n",
              "      <td>8.787760e-01</td>\n",
              "      <td>8.240085e-01</td>\n",
              "      <td>9.868586e-01</td>\n",
              "      <td>8.378619e-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.548483e+00</td>\n",
              "      <td>9.620633e-01</td>\n",
              "      <td>1.282695e+00</td>\n",
              "      <td>8.402388e-01</td>\n",
              "      <td>6.187053e-01</td>\n",
              "      <td>8.914675e-01</td>\n",
              "      <td>8.358125e-01</td>\n",
              "      <td>9.784760e-01</td>\n",
              "      <td>8.670049e-01</td>\n",
              "      <td>6.869458e-01</td>\n",
              "      <td>1.560443e+00</td>\n",
              "      <td>8.983395e-01</td>\n",
              "      <td>1.215706e+00</td>\n",
              "      <td>8.612341e-01</td>\n",
              "      <td>6.063817e-01</td>\n",
              "      <td>2.386306e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>8.669914e-01</td>\n",
              "      <td>1.919099e+01</td>\n",
              "      <td>5.601785e+01</td>\n",
              "      <td>1.882441e+01</td>\n",
              "      <td>1.712546e+01</td>\n",
              "      <td>1.844036e+00</td>\n",
              "      <td>9.703608e+01</td>\n",
              "      <td>5.744248e+00</td>\n",
              "      <td>5.498530e+00</td>\n",
              "      <td>8.452128e+00</td>\n",
              "      <td>5.776557e+00</td>\n",
              "      <td>7.922752e+01</td>\n",
              "      <td>2.799554e+01</td>\n",
              "      <td>1.372334e+02</td>\n",
              "      <td>5.186108e+01</td>\n",
              "      <td>7.922752e+01</td>\n",
              "      <td>4.136643e+01</td>\n",
              "      <td>3.449638e+00</td>\n",
              "      <td>2.020977e+01</td>\n",
              "      <td>1.329207e+01</td>\n",
              "      <td>6.861122e+01</td>\n",
              "      <td>1.103445e+00</td>\n",
              "      <td>1.009545e+01</td>\n",
              "      <td>1.712546e+01</td>\n",
              "      <td>3.729895e+00</td>\n",
              "      <td>3.960429e+01</td>\n",
              "      <td>6.136611e+01</td>\n",
              "      <td>2.054280e+00</td>\n",
              "      <td>1.799234e+01</td>\n",
              "      <td>1.631365e+00</td>\n",
              "      <td>3.290653e+00</td>\n",
              "      <td>6.861122e+01</td>\n",
              "      <td>3.804956e+01</td>\n",
              "      <td>1.754031e+00</td>\n",
              "      <td>1.686309e+01</td>\n",
              "      <td>2.423969e+01</td>\n",
              "      <td>1.847800e+01</td>\n",
              "      <td>1.372334e+02</td>\n",
              "      <td>4.594087e+00</td>\n",
              "      <td>4.338663e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>3.804956e+01</td>\n",
              "      <td>2.859842e+01</td>\n",
              "      <td>1.057253e+01</td>\n",
              "      <td>1.550682e+01</td>\n",
              "      <td>2.799554e+01</td>\n",
              "      <td>6.861122e+01</td>\n",
              "      <td>3.233162e+01</td>\n",
              "      <td>3.600202e+00</td>\n",
              "      <td>8.765070e+00</td>\n",
              "      <td>7.103451e+00</td>\n",
              "      <td>2.689581e+01</td>\n",
              "      <td>6.257618e+00</td>\n",
              "      <td>2.584172e+00</td>\n",
              "      <td>1.143269e+01</td>\n",
              "      <td>3.542033e+01</td>\n",
              "      <td>1.413707e+00</td>\n",
              "      <td>1.327399e+00</td>\n",
              "      <td>1.850471e+00</td>\n",
              "      <td>3.428049e+00</td>\n",
              "      <td>1.732116e+00</td>\n",
              "      <td>1.733296e+00</td>\n",
              "      <td>1.483054e+00</td>\n",
              "      <td>1.718861e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.548483e+00</td>\n",
              "      <td>1.567996e+00</td>\n",
              "      <td>1.282695e+00</td>\n",
              "      <td>1.741584e+00</td>\n",
              "      <td>1.263231e+00</td>\n",
              "      <td>1.722788e+00</td>\n",
              "      <td>1.743788e+00</td>\n",
              "      <td>1.483868e+00</td>\n",
              "      <td>1.593166e+00</td>\n",
              "      <td>2.162223e+00</td>\n",
              "      <td>1.560443e+00</td>\n",
              "      <td>1.454037e+00</td>\n",
              "      <td>1.215706e+00</td>\n",
              "      <td>1.564213e+00</td>\n",
              "      <td>1.664138e+00</td>\n",
              "      <td>6.566106e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 112 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          length(m)    height(cm)  ...          X2_9       area(m)\n",
              "count  1.883400e+04  1.883400e+04  ...  1.883400e+04  1.883400e+04\n",
              "mean   6.478010e-16  1.412463e-17  ... -1.094144e-13  6.733019e-17\n",
              "std    1.000027e+00  1.000027e+00  ...  1.000027e+00  1.000027e+00\n",
              "min   -1.153414e+00 -5.210778e-02  ... -2.566887e+00 -8.492320e-01\n",
              "25%   -1.153414e+00 -5.210778e-02  ... -4.513744e-01 -6.714171e-01\n",
              "50%    8.669914e-01 -5.210778e-02  ... -4.513744e-01 -4.224762e-01\n",
              "75%    8.669914e-01 -5.210778e-02  ...  6.063817e-01  2.386306e-01\n",
              "max    8.669914e-01  1.919099e+01  ...  1.664138e+00  6.566106e+00\n",
              "\n",
              "[8 rows x 112 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VIRnGTnopSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "7bf763f3-f632-4ce0-da6c-b172fb7c0483"
      },
      "source": [
        "sm = SMOTE(random_state = 2) \n",
        "X_Scaled_os, y_pet_os = sm.fit_sample(X_Scaled, y['pet_category'].ravel()) \n",
        "# X_Scaled_os, y_breed_os = sm.fit_sample(X_Scaled, y['breed_category'].ravel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBCKbz609RIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_Scaled, y, random_state = 2020, stratify=y, train_size = 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKlgrUrDAFit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MLP Classfier Model\n",
        "mlp_breed = MLPClassifier(hidden_layer_sizes=(30, 8, 2), activation = 'relu', solver = 'adam', alpha = 0.0001, learning_rate = 'adaptive', learning_rate_init= 0.0005, max_iter= 2000, random_state= 2020, verbose = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBZFBFdBDho5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "546a16fb-685f-4eba-9a79-e7f3dc1756ed"
      },
      "source": [
        "mlp_breed.fit(X_Scaled, y['breed_category'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.14801967\n",
            "Iteration 2, loss = 1.03751937\n",
            "Iteration 3, loss = 0.87623991\n",
            "Iteration 4, loss = 0.74461400\n",
            "Iteration 5, loss = 0.68703672\n",
            "Iteration 6, loss = 0.65513451\n",
            "Iteration 7, loss = 0.63221034\n",
            "Iteration 8, loss = 0.61351476\n",
            "Iteration 9, loss = 0.59752734\n",
            "Iteration 10, loss = 0.58265863\n",
            "Iteration 11, loss = 0.56824266\n",
            "Iteration 12, loss = 0.55395912\n",
            "Iteration 13, loss = 0.53976589\n",
            "Iteration 14, loss = 0.52775202\n",
            "Iteration 15, loss = 0.51580081\n",
            "Iteration 16, loss = 0.50425011\n",
            "Iteration 17, loss = 0.49456370\n",
            "Iteration 18, loss = 0.48392698\n",
            "Iteration 19, loss = 0.47460304\n",
            "Iteration 20, loss = 0.46513494\n",
            "Iteration 21, loss = 0.45517912\n",
            "Iteration 22, loss = 0.44718875\n",
            "Iteration 23, loss = 0.43859692\n",
            "Iteration 24, loss = 0.43100198\n",
            "Iteration 25, loss = 0.42255507\n",
            "Iteration 26, loss = 0.41565653\n",
            "Iteration 27, loss = 0.40844068\n",
            "Iteration 28, loss = 0.40234934\n",
            "Iteration 29, loss = 0.39593080\n",
            "Iteration 30, loss = 0.38892555\n",
            "Iteration 31, loss = 0.38327574\n",
            "Iteration 32, loss = 0.37733811\n",
            "Iteration 33, loss = 0.37204398\n",
            "Iteration 34, loss = 0.32559458\n",
            "Iteration 35, loss = 0.26735812\n",
            "Iteration 36, loss = 0.25270609\n",
            "Iteration 37, loss = 0.24167575\n",
            "Iteration 38, loss = 0.23353142\n",
            "Iteration 39, loss = 0.22569321\n",
            "Iteration 40, loss = 0.21868255\n",
            "Iteration 41, loss = 0.21370088\n",
            "Iteration 42, loss = 0.20863782\n",
            "Iteration 43, loss = 0.20327828\n",
            "Iteration 44, loss = 0.19875052\n",
            "Iteration 45, loss = 0.19516938\n",
            "Iteration 46, loss = 0.19007792\n",
            "Iteration 47, loss = 0.18655060\n",
            "Iteration 48, loss = 0.18318090\n",
            "Iteration 49, loss = 0.18055352\n",
            "Iteration 50, loss = 0.17747990\n",
            "Iteration 51, loss = 0.17543948\n",
            "Iteration 52, loss = 0.17311624\n",
            "Iteration 53, loss = 0.17124912\n",
            "Iteration 54, loss = 0.16894874\n",
            "Iteration 55, loss = 0.16754957\n",
            "Iteration 56, loss = 0.16571124\n",
            "Iteration 57, loss = 0.16382499\n",
            "Iteration 58, loss = 0.16195461\n",
            "Iteration 59, loss = 0.16053092\n",
            "Iteration 60, loss = 0.15897502\n",
            "Iteration 61, loss = 0.15780398\n",
            "Iteration 62, loss = 0.15754019\n",
            "Iteration 63, loss = 0.15545512\n",
            "Iteration 64, loss = 0.15443145\n",
            "Iteration 65, loss = 0.15377243\n",
            "Iteration 66, loss = 0.15268424\n",
            "Iteration 67, loss = 0.15180474\n",
            "Iteration 68, loss = 0.15064421\n",
            "Iteration 69, loss = 0.15024056\n",
            "Iteration 70, loss = 0.14900433\n",
            "Iteration 71, loss = 0.14802440\n",
            "Iteration 72, loss = 0.14765607\n",
            "Iteration 73, loss = 0.14753999\n",
            "Iteration 74, loss = 0.14607536\n",
            "Iteration 75, loss = 0.14543903\n",
            "Iteration 76, loss = 0.14496700\n",
            "Iteration 77, loss = 0.14399957\n",
            "Iteration 78, loss = 0.14425453\n",
            "Iteration 79, loss = 0.14339905\n",
            "Iteration 80, loss = 0.14226362\n",
            "Iteration 81, loss = 0.14195228\n",
            "Iteration 82, loss = 0.14170736\n",
            "Iteration 83, loss = 0.14090447\n",
            "Iteration 84, loss = 0.14017460\n",
            "Iteration 85, loss = 0.13938439\n",
            "Iteration 86, loss = 0.13999342\n",
            "Iteration 87, loss = 0.13864825\n",
            "Iteration 88, loss = 0.13844625\n",
            "Iteration 89, loss = 0.13807791\n",
            "Iteration 90, loss = 0.13733661\n",
            "Iteration 91, loss = 0.13685597\n",
            "Iteration 92, loss = 0.13719679\n",
            "Iteration 93, loss = 0.13635256\n",
            "Iteration 94, loss = 0.13617482\n",
            "Iteration 95, loss = 0.13661363\n",
            "Iteration 96, loss = 0.13553867\n",
            "Iteration 97, loss = 0.13552540\n",
            "Iteration 98, loss = 0.13490336\n",
            "Iteration 99, loss = 0.13404537\n",
            "Iteration 100, loss = 0.13426321\n",
            "Iteration 101, loss = 0.13465567\n",
            "Iteration 102, loss = 0.13388455\n",
            "Iteration 103, loss = 0.13397603\n",
            "Iteration 104, loss = 0.13382862\n",
            "Iteration 105, loss = 0.13357939\n",
            "Iteration 106, loss = 0.13294670\n",
            "Iteration 107, loss = 0.13240804\n",
            "Iteration 108, loss = 0.13234303\n",
            "Iteration 109, loss = 0.13255179\n",
            "Iteration 110, loss = 0.13170768\n",
            "Iteration 111, loss = 0.13112578\n",
            "Iteration 112, loss = 0.13100130\n",
            "Iteration 113, loss = 0.13123442\n",
            "Iteration 114, loss = 0.13093540\n",
            "Iteration 115, loss = 0.13073812\n",
            "Iteration 116, loss = 0.13068841\n",
            "Iteration 117, loss = 0.13033703\n",
            "Iteration 118, loss = 0.13051843\n",
            "Iteration 119, loss = 0.12994901\n",
            "Iteration 120, loss = 0.12907965\n",
            "Iteration 121, loss = 0.12930015\n",
            "Iteration 122, loss = 0.12879016\n",
            "Iteration 123, loss = 0.12969146\n",
            "Iteration 124, loss = 0.12863683\n",
            "Iteration 125, loss = 0.12819021\n",
            "Iteration 126, loss = 0.12819050\n",
            "Iteration 127, loss = 0.12769082\n",
            "Iteration 128, loss = 0.12844171\n",
            "Iteration 129, loss = 0.12807744\n",
            "Iteration 130, loss = 0.12792380\n",
            "Iteration 131, loss = 0.12818249\n",
            "Iteration 132, loss = 0.12801320\n",
            "Iteration 133, loss = 0.12789196\n",
            "Iteration 134, loss = 0.12736672\n",
            "Iteration 135, loss = 0.12777746\n",
            "Iteration 136, loss = 0.12633228\n",
            "Iteration 137, loss = 0.12652273\n",
            "Iteration 138, loss = 0.12680716\n",
            "Iteration 139, loss = 0.12680966\n",
            "Iteration 140, loss = 0.12588043\n",
            "Iteration 141, loss = 0.12599630\n",
            "Iteration 142, loss = 0.12566625\n",
            "Iteration 143, loss = 0.12557815\n",
            "Iteration 144, loss = 0.12539187\n",
            "Iteration 145, loss = 0.12588684\n",
            "Iteration 146, loss = 0.12495001\n",
            "Iteration 147, loss = 0.12516900\n",
            "Iteration 148, loss = 0.12413042\n",
            "Iteration 149, loss = 0.12478979\n",
            "Iteration 150, loss = 0.12448658\n",
            "Iteration 151, loss = 0.12390691\n",
            "Iteration 152, loss = 0.12467454\n",
            "Iteration 153, loss = 0.12469071\n",
            "Iteration 154, loss = 0.12404895\n",
            "Iteration 155, loss = 0.12391733\n",
            "Iteration 156, loss = 0.12349558\n",
            "Iteration 157, loss = 0.12294638\n",
            "Iteration 158, loss = 0.12177930\n",
            "Iteration 159, loss = 0.12181093\n",
            "Iteration 160, loss = 0.12189551\n",
            "Iteration 161, loss = 0.12098527\n",
            "Iteration 162, loss = 0.12105987\n",
            "Iteration 163, loss = 0.12128795\n",
            "Iteration 164, loss = 0.12135240\n",
            "Iteration 165, loss = 0.12100704\n",
            "Iteration 166, loss = 0.12098708\n",
            "Iteration 167, loss = 0.11950904\n",
            "Iteration 168, loss = 0.12050742\n",
            "Iteration 169, loss = 0.12007942\n",
            "Iteration 170, loss = 0.12065892\n",
            "Iteration 171, loss = 0.11996006\n",
            "Iteration 172, loss = 0.11988129\n",
            "Iteration 173, loss = 0.12068116\n",
            "Iteration 174, loss = 0.11974989\n",
            "Iteration 175, loss = 0.11937867\n",
            "Iteration 176, loss = 0.11960714\n",
            "Iteration 177, loss = 0.11972687\n",
            "Iteration 178, loss = 0.12000328\n",
            "Iteration 179, loss = 0.11880341\n",
            "Iteration 180, loss = 0.11904314\n",
            "Iteration 181, loss = 0.11848265\n",
            "Iteration 182, loss = 0.11850420\n",
            "Iteration 183, loss = 0.11918537\n",
            "Iteration 184, loss = 0.11783796\n",
            "Iteration 185, loss = 0.11879134\n",
            "Iteration 186, loss = 0.11876868\n",
            "Iteration 187, loss = 0.11902115\n",
            "Iteration 188, loss = 0.11784795\n",
            "Iteration 189, loss = 0.11814999\n",
            "Iteration 190, loss = 0.11805013\n",
            "Iteration 191, loss = 0.11731901\n",
            "Iteration 192, loss = 0.11776823\n",
            "Iteration 193, loss = 0.11801963\n",
            "Iteration 194, loss = 0.11762093\n",
            "Iteration 195, loss = 0.11717291\n",
            "Iteration 196, loss = 0.11648775\n",
            "Iteration 197, loss = 0.11671456\n",
            "Iteration 198, loss = 0.11642730\n",
            "Iteration 199, loss = 0.11638218\n",
            "Iteration 200, loss = 0.11549501\n",
            "Iteration 201, loss = 0.11643719\n",
            "Iteration 202, loss = 0.11633628\n",
            "Iteration 203, loss = 0.11532210\n",
            "Iteration 204, loss = 0.11502323\n",
            "Iteration 205, loss = 0.11555421\n",
            "Iteration 206, loss = 0.11667622\n",
            "Iteration 207, loss = 0.11440026\n",
            "Iteration 208, loss = 0.11406708\n",
            "Iteration 209, loss = 0.11476084\n",
            "Iteration 210, loss = 0.11447871\n",
            "Iteration 211, loss = 0.11485289\n",
            "Iteration 212, loss = 0.11432908\n",
            "Iteration 213, loss = 0.11390890\n",
            "Iteration 214, loss = 0.11399974\n",
            "Iteration 215, loss = 0.11329465\n",
            "Iteration 216, loss = 0.11415871\n",
            "Iteration 217, loss = 0.11338774\n",
            "Iteration 218, loss = 0.11334932\n",
            "Iteration 219, loss = 0.11290058\n",
            "Iteration 220, loss = 0.11282849\n",
            "Iteration 221, loss = 0.11268575\n",
            "Iteration 222, loss = 0.11245730\n",
            "Iteration 223, loss = 0.11257535\n",
            "Iteration 224, loss = 0.11262283\n",
            "Iteration 225, loss = 0.11275277\n",
            "Iteration 226, loss = 0.11244829\n",
            "Iteration 227, loss = 0.11281095\n",
            "Iteration 228, loss = 0.11271888\n",
            "Iteration 229, loss = 0.11236106\n",
            "Iteration 230, loss = 0.11262675\n",
            "Iteration 231, loss = 0.11359724\n",
            "Iteration 232, loss = 0.11370428\n",
            "Iteration 233, loss = 0.11255286\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(30, 8, 2), learning_rate='adaptive',\n",
              "              learning_rate_init=0.0005, max_fun=15000, max_iter=2000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=2020, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN6MNou6EFG0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "83eb1fdc-2e36-4d55-93a6-313d7f66d271"
      },
      "source": [
        "y_pred_breed = mlp_breed.predict(X_test)\n",
        "breed_val = pd.DataFrame({'ACTUALS': y_test['breed_category'], 'PREDICTED': y_pred_breed})\n",
        "pd.crosstab(breed_val['ACTUALS'], breed_val['PREDICTED'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>PREDICTED</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ACTUALS</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1740</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>127</td>\n",
              "      <td>1544</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "PREDICTED     0     1    2\n",
              "ACTUALS                   \n",
              "0          1740    60    0\n",
              "1           127  1544    0\n",
              "2             0     5  291"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWbKt-ZkFPXz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7dab132-6895-4454-d36f-42189e70f937"
      },
      "source": [
        "f1_score(breed_val['ACTUALS'], breed_val['PREDICTED'], average= 'weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9489971902921917"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SusOLYcGFpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_pet = MLPClassifier(hidden_layer_sizes=(30, 8, 2), activation = 'relu', solver = 'adam', alpha = 0.0001, learning_rate = 'adaptive', learning_rate_init= 0.0005, max_iter= 2000, random_state= 2020, verbose = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70zBSPAVF3up",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37f7fa52-091f-4236-f293-70a2a4e91b42"
      },
      "source": [
        "mlp_pet.fit(X_Scaled_os, y_pet_os)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.40409023\n",
            "Iteration 2, loss = 0.88234668\n",
            "Iteration 3, loss = 0.60042901\n",
            "Iteration 4, loss = 0.50784020\n",
            "Iteration 5, loss = 0.46810762\n",
            "Iteration 6, loss = 0.43835303\n",
            "Iteration 7, loss = 0.41393099\n",
            "Iteration 8, loss = 0.39282983\n",
            "Iteration 9, loss = 0.37419701\n",
            "Iteration 10, loss = 0.35680630\n",
            "Iteration 11, loss = 0.34090776\n",
            "Iteration 12, loss = 0.32722268\n",
            "Iteration 13, loss = 0.31584526\n",
            "Iteration 14, loss = 0.30442567\n",
            "Iteration 15, loss = 0.29457555\n",
            "Iteration 16, loss = 0.28601637\n",
            "Iteration 17, loss = 0.27791093\n",
            "Iteration 18, loss = 0.27072588\n",
            "Iteration 19, loss = 0.26383869\n",
            "Iteration 20, loss = 0.25816070\n",
            "Iteration 21, loss = 0.25210085\n",
            "Iteration 22, loss = 0.24751473\n",
            "Iteration 23, loss = 0.24219497\n",
            "Iteration 24, loss = 0.23829526\n",
            "Iteration 25, loss = 0.23426175\n",
            "Iteration 26, loss = 0.23066076\n",
            "Iteration 27, loss = 0.22679414\n",
            "Iteration 28, loss = 0.22374476\n",
            "Iteration 29, loss = 0.21940828\n",
            "Iteration 30, loss = 0.21489177\n",
            "Iteration 31, loss = 0.21215269\n",
            "Iteration 32, loss = 0.20893748\n",
            "Iteration 33, loss = 0.20671265\n",
            "Iteration 34, loss = 0.20336577\n",
            "Iteration 35, loss = 0.20046598\n",
            "Iteration 36, loss = 0.19799243\n",
            "Iteration 37, loss = 0.19591370\n",
            "Iteration 38, loss = 0.19336566\n",
            "Iteration 39, loss = 0.19125310\n",
            "Iteration 40, loss = 0.18910773\n",
            "Iteration 41, loss = 0.18701812\n",
            "Iteration 42, loss = 0.18537795\n",
            "Iteration 43, loss = 0.18285667\n",
            "Iteration 44, loss = 0.18113852\n",
            "Iteration 45, loss = 0.17935261\n",
            "Iteration 46, loss = 0.17798394\n",
            "Iteration 47, loss = 0.17605637\n",
            "Iteration 48, loss = 0.17529156\n",
            "Iteration 49, loss = 0.17405567\n",
            "Iteration 50, loss = 0.17151404\n",
            "Iteration 51, loss = 0.17086775\n",
            "Iteration 52, loss = 0.17010826\n",
            "Iteration 53, loss = 0.16779540\n",
            "Iteration 54, loss = 0.16652318\n",
            "Iteration 55, loss = 0.16545757\n",
            "Iteration 56, loss = 0.16424996\n",
            "Iteration 57, loss = 0.16381534\n",
            "Iteration 58, loss = 0.16283643\n",
            "Iteration 59, loss = 0.16149568\n",
            "Iteration 60, loss = 0.15997169\n",
            "Iteration 61, loss = 0.15969362\n",
            "Iteration 62, loss = 0.15890703\n",
            "Iteration 63, loss = 0.15814645\n",
            "Iteration 64, loss = 0.15711701\n",
            "Iteration 65, loss = 0.15624738\n",
            "Iteration 66, loss = 0.15586895\n",
            "Iteration 67, loss = 0.15505623\n",
            "Iteration 68, loss = 0.15396583\n",
            "Iteration 69, loss = 0.15345555\n",
            "Iteration 70, loss = 0.15436746\n",
            "Iteration 71, loss = 0.15806066\n",
            "Iteration 72, loss = 0.15251265\n",
            "Iteration 73, loss = 0.15200022\n",
            "Iteration 74, loss = 0.15119332\n",
            "Iteration 75, loss = 0.15097742\n",
            "Iteration 76, loss = 0.14944710\n",
            "Iteration 77, loss = 0.14895527\n",
            "Iteration 78, loss = 0.14990939\n",
            "Iteration 79, loss = 0.14812344\n",
            "Iteration 80, loss = 0.14827247\n",
            "Iteration 81, loss = 0.14706463\n",
            "Iteration 82, loss = 0.14714024\n",
            "Iteration 83, loss = 0.14634485\n",
            "Iteration 84, loss = 0.14549283\n",
            "Iteration 85, loss = 0.14485832\n",
            "Iteration 86, loss = 0.14508554\n",
            "Iteration 87, loss = 0.14481941\n",
            "Iteration 88, loss = 0.14394031\n",
            "Iteration 89, loss = 0.14373827\n",
            "Iteration 90, loss = 0.14306602\n",
            "Iteration 91, loss = 0.14388162\n",
            "Iteration 92, loss = 0.14289731\n",
            "Iteration 93, loss = 0.14203224\n",
            "Iteration 94, loss = 0.14192401\n",
            "Iteration 95, loss = 0.14101364\n",
            "Iteration 96, loss = 0.14197883\n",
            "Iteration 97, loss = 0.14077330\n",
            "Iteration 98, loss = 0.14026983\n",
            "Iteration 99, loss = 0.14031231\n",
            "Iteration 100, loss = 0.13971377\n",
            "Iteration 101, loss = 0.13917086\n",
            "Iteration 102, loss = 0.13874986\n",
            "Iteration 103, loss = 0.13887928\n",
            "Iteration 104, loss = 0.13943649\n",
            "Iteration 105, loss = 0.14043827\n",
            "Iteration 106, loss = 0.13983916\n",
            "Iteration 107, loss = 0.13855605\n",
            "Iteration 108, loss = 0.13774947\n",
            "Iteration 109, loss = 0.13733565\n",
            "Iteration 110, loss = 0.13674531\n",
            "Iteration 111, loss = 0.13628495\n",
            "Iteration 112, loss = 0.13619029\n",
            "Iteration 113, loss = 0.13598050\n",
            "Iteration 114, loss = 0.13704701\n",
            "Iteration 115, loss = 0.13662900\n",
            "Iteration 116, loss = 0.13509559\n",
            "Iteration 117, loss = 0.13592338\n",
            "Iteration 118, loss = 0.13494448\n",
            "Iteration 119, loss = 0.13510915\n",
            "Iteration 120, loss = 0.13447490\n",
            "Iteration 121, loss = 0.13406263\n",
            "Iteration 122, loss = 0.13426935\n",
            "Iteration 123, loss = 0.13346938\n",
            "Iteration 124, loss = 0.13370229\n",
            "Iteration 125, loss = 0.13381516\n",
            "Iteration 126, loss = 0.13282376\n",
            "Iteration 127, loss = 0.13230888\n",
            "Iteration 128, loss = 0.13264500\n",
            "Iteration 129, loss = 0.13232718\n",
            "Iteration 130, loss = 0.13255364\n",
            "Iteration 131, loss = 0.13210190\n",
            "Iteration 132, loss = 0.13227705\n",
            "Iteration 133, loss = 0.13188473\n",
            "Iteration 134, loss = 0.13202878\n",
            "Iteration 135, loss = 0.13139656\n",
            "Iteration 136, loss = 0.13129198\n",
            "Iteration 137, loss = 0.13662441\n",
            "Iteration 138, loss = 0.13146506\n",
            "Iteration 139, loss = 0.13092642\n",
            "Iteration 140, loss = 0.13137986\n",
            "Iteration 141, loss = 0.13073473\n",
            "Iteration 142, loss = 0.13075194\n",
            "Iteration 143, loss = 0.13069507\n",
            "Iteration 144, loss = 0.12980015\n",
            "Iteration 145, loss = 0.13083586\n",
            "Iteration 146, loss = 0.12986512\n",
            "Iteration 147, loss = 0.12944244\n",
            "Iteration 148, loss = 0.12907902\n",
            "Iteration 149, loss = 0.12899564\n",
            "Iteration 150, loss = 0.12928568\n",
            "Iteration 151, loss = 0.12883486\n",
            "Iteration 152, loss = 0.12813893\n",
            "Iteration 153, loss = 0.12865185\n",
            "Iteration 154, loss = 0.13126374\n",
            "Iteration 155, loss = 0.13038831\n",
            "Iteration 156, loss = 0.12806847\n",
            "Iteration 157, loss = 0.12815488\n",
            "Iteration 158, loss = 0.12778117\n",
            "Iteration 159, loss = 0.12761267\n",
            "Iteration 160, loss = 0.12734461\n",
            "Iteration 161, loss = 0.12723722\n",
            "Iteration 162, loss = 0.12738022\n",
            "Iteration 163, loss = 0.13045123\n",
            "Iteration 164, loss = 0.12699032\n",
            "Iteration 165, loss = 0.12648742\n",
            "Iteration 166, loss = 0.12726468\n",
            "Iteration 167, loss = 0.12660456\n",
            "Iteration 168, loss = 0.12696911\n",
            "Iteration 169, loss = 0.12652624\n",
            "Iteration 170, loss = 0.12768894\n",
            "Iteration 171, loss = 0.12749584\n",
            "Iteration 172, loss = 0.12668505\n",
            "Iteration 173, loss = 0.12572939\n",
            "Iteration 174, loss = 0.12667687\n",
            "Iteration 175, loss = 0.12513511\n",
            "Iteration 176, loss = 0.12508553\n",
            "Iteration 177, loss = 0.12554371\n",
            "Iteration 178, loss = 0.12651403\n",
            "Iteration 179, loss = 0.12623540\n",
            "Iteration 180, loss = 0.12466265\n",
            "Iteration 181, loss = 0.12638270\n",
            "Iteration 182, loss = 0.12444425\n",
            "Iteration 183, loss = 0.12425486\n",
            "Iteration 184, loss = 0.12473600\n",
            "Iteration 185, loss = 0.12397108\n",
            "Iteration 186, loss = 0.12421568\n",
            "Iteration 187, loss = 0.12428477\n",
            "Iteration 188, loss = 0.12368175\n",
            "Iteration 189, loss = 0.12358899\n",
            "Iteration 190, loss = 0.12385666\n",
            "Iteration 191, loss = 0.12370265\n",
            "Iteration 192, loss = 0.12334927\n",
            "Iteration 193, loss = 0.12337644\n",
            "Iteration 194, loss = 0.12562657\n",
            "Iteration 195, loss = 0.12309169\n",
            "Iteration 196, loss = 0.12338394\n",
            "Iteration 197, loss = 0.12290739\n",
            "Iteration 198, loss = 0.12282827\n",
            "Iteration 199, loss = 0.12290993\n",
            "Iteration 200, loss = 0.12178310\n",
            "Iteration 201, loss = 0.12245762\n",
            "Iteration 202, loss = 0.12185899\n",
            "Iteration 203, loss = 0.12139316\n",
            "Iteration 204, loss = 0.12205205\n",
            "Iteration 205, loss = 0.12347189\n",
            "Iteration 206, loss = 0.12278295\n",
            "Iteration 207, loss = 0.12173199\n",
            "Iteration 208, loss = 0.12174562\n",
            "Iteration 209, loss = 0.12168493\n",
            "Iteration 210, loss = 0.12101734\n",
            "Iteration 211, loss = 0.12147654\n",
            "Iteration 212, loss = 0.12075487\n",
            "Iteration 213, loss = 0.12404157\n",
            "Iteration 214, loss = 0.12094260\n",
            "Iteration 215, loss = 0.12130450\n",
            "Iteration 216, loss = 0.12094115\n",
            "Iteration 217, loss = 0.12098574\n",
            "Iteration 218, loss = 0.12052389\n",
            "Iteration 219, loss = 0.12075828\n",
            "Iteration 220, loss = 0.12127320\n",
            "Iteration 221, loss = 0.12076148\n",
            "Iteration 222, loss = 0.11961448\n",
            "Iteration 223, loss = 0.11999436\n",
            "Iteration 224, loss = 0.11930131\n",
            "Iteration 225, loss = 0.11988152\n",
            "Iteration 226, loss = 0.12333959\n",
            "Iteration 227, loss = 0.12361084\n",
            "Iteration 228, loss = 0.12496194\n",
            "Iteration 229, loss = 0.12085639\n",
            "Iteration 230, loss = 0.11902126\n",
            "Iteration 231, loss = 0.11922794\n",
            "Iteration 232, loss = 0.11940358\n",
            "Iteration 233, loss = 0.11999822\n",
            "Iteration 234, loss = 0.11882498\n",
            "Iteration 235, loss = 0.11955363\n",
            "Iteration 236, loss = 0.11927098\n",
            "Iteration 237, loss = 0.11921439\n",
            "Iteration 238, loss = 0.11965541\n",
            "Iteration 239, loss = 0.11836579\n",
            "Iteration 240, loss = 0.11805334\n",
            "Iteration 241, loss = 0.11819548\n",
            "Iteration 242, loss = 0.11873499\n",
            "Iteration 243, loss = 0.11954382\n",
            "Iteration 244, loss = 0.11817802\n",
            "Iteration 245, loss = 0.11886723\n",
            "Iteration 246, loss = 0.11810690\n",
            "Iteration 247, loss = 0.11932419\n",
            "Iteration 248, loss = 0.11829677\n",
            "Iteration 249, loss = 0.11769961\n",
            "Iteration 250, loss = 0.11861274\n",
            "Iteration 251, loss = 0.11822388\n",
            "Iteration 252, loss = 0.11825244\n",
            "Iteration 253, loss = 0.11716674\n",
            "Iteration 254, loss = 0.11788814\n",
            "Iteration 255, loss = 0.11776805\n",
            "Iteration 256, loss = 0.11704704\n",
            "Iteration 257, loss = 0.12063860\n",
            "Iteration 258, loss = 0.11818172\n",
            "Iteration 259, loss = 0.11833922\n",
            "Iteration 260, loss = 0.11715497\n",
            "Iteration 261, loss = 0.11698879\n",
            "Iteration 262, loss = 0.11792514\n",
            "Iteration 263, loss = 0.11876174\n",
            "Iteration 264, loss = 0.11805620\n",
            "Iteration 265, loss = 0.11704650\n",
            "Iteration 266, loss = 0.11663273\n",
            "Iteration 267, loss = 0.11740436\n",
            "Iteration 268, loss = 0.11613859\n",
            "Iteration 269, loss = 0.11745573\n",
            "Iteration 270, loss = 0.11644444\n",
            "Iteration 271, loss = 0.11679645\n",
            "Iteration 272, loss = 0.11659145\n",
            "Iteration 273, loss = 0.11688235\n",
            "Iteration 274, loss = 0.11691954\n",
            "Iteration 275, loss = 0.12237810\n",
            "Iteration 276, loss = 0.12420772\n",
            "Iteration 277, loss = 0.11959863\n",
            "Iteration 278, loss = 0.11609100\n",
            "Iteration 279, loss = 0.11666601\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(30, 8, 2), learning_rate='adaptive',\n",
              "              learning_rate_init=0.0005, max_fun=15000, max_iter=2000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=2020, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sElVidG3GUAH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "00f9221e-3bbe-4fba-f5a5-cbc1c3ffd718"
      },
      "source": [
        "y_pred_pet = mlp_pet.predict(X_test)\n",
        "pet_val = pd.DataFrame({'ACTUALS': y_test['pet_category'], 'PREDICTED': y_pred_pet})\n",
        "pd.crosstab(pet_val['ACTUALS'], pet_val['PREDICTED'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>PREDICTED</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ACTUALS</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1256</td>\n",
              "      <td>177</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>113</td>\n",
              "      <td>1999</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "PREDICTED   0     1     2    4\n",
              "ACTUALS                       \n",
              "0          17     0     0    0\n",
              "1           3  1256   177    1\n",
              "2           0   113  1999   12\n",
              "4           0     0     2  187"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOfvnGCZGnFM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70a67a20-e9a3-41c5-9f7e-2c3131ac9d3d"
      },
      "source": [
        "f1_score(pet_val['ACTUALS'], pet_val['PREDICTED'], average= 'weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9178867234714158"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhR9Wc-wIMBM",
        "colab_type": "text"
      },
      "source": [
        "#Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdJoi8yTILhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv('testPetID.csv')\n",
        "#Fill missing values for condition column\n",
        "test_df['condition'].fillna('missing', inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mBmujASiHsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['area(m)'] = test_df['length(m)'] * test_df['height(cm)'] /100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHGFJUfVIeCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# converting respective columns into respective data_types\n",
        "test_df = convert_to_datatype(test_df, ['pet_id', 'condition', 'color_type', 'X1', 'X2'], 'category')\n",
        "test_df = convert_to_datatype(test_df, ['issue_date', 'listing_date'], 'datetime64[ns]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO7pGWzGJHyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert time data into differences\n",
        "test_df = create_datetime_features(test_df, ['issue_date', 'listing_date'])\n",
        "test_df['listing_issue_diff'] = test_df['listing_date'] - test_df['issue_date']\n",
        "test_df['listing_issue_diff'] = test_df['listing_issue_diff'].dt.days\n",
        "\n",
        "#One-Hot Encoding Categorical Data \n",
        "test_df = pd.get_dummies(columns = ['condition', 'color_type', 'X1', 'X2'], data= test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr1NfUFkKGDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_upload = test_df.drop( ['pet_id', 'issue_date', 'listing_date'] , axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd_KsKzMKt74",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "841e7c98-df5a-4288-889b-e981fce245a1"
      },
      "source": [
        "set(list(X_Scaled)) - set(list(X_test_upload))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'X1_19', 'X1_3', 'color_type_Black Tiger', 'color_type_Brown Tiger'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkOAbqX5K0td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in ['X1_19', 'X1_3', 'color_type_Black Tiger', 'color_type_Brown Tiger']:\n",
        "  X_test_upload[i] = 0\n",
        "X_test_scaled = sc.transform(X_test_upload[cols_to_scale])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgQGqtIWLUck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_breed_op = mlp_breed.predict(X_test_scaled)\n",
        "y_test_pet_op = mlp_pet.predict(X_test_scaled)\n",
        "results = pd.DataFrame( { 'pet_id': test_df['pet_id'], 'breed_category': y_test_breed_op, 'pet_category': y_test_pet_op  })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1WV2JsTNQMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "46e50bb8-b453-41ad-946e-376fa4740474"
      },
      "source": [
        "results.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pet_id</th>\n",
              "      <th>breed_category</th>\n",
              "      <th>pet_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ANSL_75005</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ANSL_76663</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ANSL_58259</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ANSL_67171</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ANSL_72871</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       pet_id  breed_category  pet_category\n",
              "0  ANSL_75005               1             2\n",
              "1  ANSL_76663               0             1\n",
              "2  ANSL_58259               0             2\n",
              "3  ANSL_67171               0             2\n",
              "4  ANSL_72871               0             2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzb_pXETNUlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results.to_csv('result005.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}